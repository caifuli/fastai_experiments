{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT-Binary.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-m68jlCKyeAO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":649},"outputId":"97960ba3-e74c-4603-ca33-399624e70313","executionInfo":{"status":"ok","timestamp":1572124010690,"user_tz":-330,"elapsed":13060,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["!pip install pytorch-transformers\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch-transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n","\u001b[K     |████████████████████████████████| 184kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n","Collecting regex\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 51.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.253)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.3.0+cu100)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.17.3)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 44.9MB/s \n","\u001b[?25hCollecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 45.2MB/s \n","\u001b[?25hRequirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.9.11)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.253 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.253)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.14.0)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.253->boto3->pytorch-transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.253->boto3->pytorch-transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=ff39d27f48faf0b4a812c92a394770178736f5b04c2a67930f3433cd3657c809\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","Successfully built sacremoses\n","Installing collected packages: regex, sacremoses, sentencepiece, pytorch-transformers\n","Successfully installed pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.35 sentencepiece-0.1.83\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oVd95WcWyla_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"a727f20a-8c6c-49ba-bc58-91fa16e1e001","executionInfo":{"status":"ok","timestamp":1572124027593,"user_tz":-330,"elapsed":29947,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["\n","!mkdir data\n","!wget https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz -O data/data.tgz"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2019-10-26 21:06:54--  https://s3.amazonaws.com/fast-ai-nlp/yelp_review_polarity_csv.tgz\n","Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.114.5\n","Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.114.5|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 166373201 (159M) [application/x-tar]\n","Saving to: ‘data/data.tgz’\n","\n","data/data.tgz       100%[===================>] 158.67M  15.9MB/s    in 11s     \n","\n","2019-10-26 21:07:06 (14.4 MB/s) - ‘data/data.tgz’ saved [166373201/166373201]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"C1S48gDPyrVU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"d2d6656b-4e3f-4edd-c013-960727690614","executionInfo":{"status":"ok","timestamp":1572124042753,"user_tz":-330,"elapsed":45093,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["\n","!tar -xvzf data/data.tgz -C data/\n","!mv data/yelp_review_polarity_csv/* data/\n","!rm -r data/yelp_review_polarity_csv/\n","!rm data/data.tgz"],"execution_count":3,"outputs":[{"output_type":"stream","text":["yelp_review_polarity_csv/\n","yelp_review_polarity_csv/train.csv\n","yelp_review_polarity_csv/readme.txt\n","yelp_review_polarity_csv/test.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0gwVVE1gy53m","colab_type":"code","colab":{}},"source":["import pandas as pd\n","from tqdm import tqdm_notebook\n","\n","prefix = 'data/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ElYVpmzyy7ic","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"10082674-29a0-453c-f43b-2cdb9295cffc","executionInfo":{"status":"ok","timestamp":1572124046643,"user_tz":-330,"elapsed":48961,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["train_df = pd.read_csv(prefix + 'train.csv', header=None)\n","train_df.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Unfortunately, the frustration of being Dr. Go...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Been going to Dr. Goldberg for over 10 years. ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>I don't know what Dr. Goldberg was like before...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>I'm writing this review to give you a heads up...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>All the food is great here. But the best thing...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0                                                  1\n","0  1  Unfortunately, the frustration of being Dr. Go...\n","1  2  Been going to Dr. Goldberg for over 10 years. ...\n","2  1  I don't know what Dr. Goldberg was like before...\n","3  1  I'm writing this review to give you a heads up...\n","4  2  All the food is great here. But the best thing..."]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"Ai3JqNgzy9vJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"9c84ce13-3f85-4dfd-877d-023b86d0a6ac","executionInfo":{"status":"ok","timestamp":1572124046645,"user_tz":-330,"elapsed":48952,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["test_df = pd.read_csv(prefix + 'test.csv', header=None)\n","test_df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>Contrary to other reviews, I have zero complai...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Last summer I had an appointment to get new ti...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Friendly staff, same starbucks fair you get an...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>The food is good. Unfortunately the service is...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>Even when we didn't have a car Filene's Baseme...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0                                                  1\n","0  2  Contrary to other reviews, I have zero complai...\n","1  1  Last summer I had an appointment to get new ti...\n","2  2  Friendly staff, same starbucks fair you get an...\n","3  1  The food is good. Unfortunately the service is...\n","4  2  Even when we didn't have a car Filene's Baseme..."]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"baztkFohy_vt","colab_type":"code","colab":{}},"source":["\n","train_df[0] = (train_df[0] == 2).astype(int)\n","test_df[0] = (test_df[0] == 2).astype(int)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jW5K_k6szCi8","colab_type":"code","colab":{}},"source":["\n","train_df = pd.DataFrame({\n","    'id':range(len(train_df)),\n","    'label':train_df[0],\n","    'alpha':['a']*train_df.shape[0],\n","    'text': train_df[1].replace(r'\\n', ' ', regex=True)\n","})\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywwEGRZrzD4p","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":669},"outputId":"903c14ce-c20a-42a7-844f-de5fa6e93f7b","executionInfo":{"status":"ok","timestamp":1572124047150,"user_tz":-330,"elapsed":49426,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["train_df.sample(20)\n"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>alpha</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2430</th>\n","      <td>2430</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>I didn't really know what to expect from Lidia...</td>\n","    </tr>\n","    <tr>\n","      <th>331013</th>\n","      <td>331013</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>We absolutely love Costa Vida, but I have to a...</td>\n","    </tr>\n","    <tr>\n","      <th>510602</th>\n","      <td>510602</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>The only reason we stayed at this place is bec...</td>\n","    </tr>\n","    <tr>\n","      <th>364277</th>\n","      <td>364277</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>This was the most over rated restaurant I have...</td>\n","    </tr>\n","    <tr>\n","      <th>297591</th>\n","      <td>297591</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>First time I came here it was the middle of Ju...</td>\n","    </tr>\n","    <tr>\n","      <th>359799</th>\n","      <td>359799</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>My son and I stood at the front for 6 mins. We...</td>\n","    </tr>\n","    <tr>\n","      <th>447821</th>\n","      <td>447821</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>Great little spot. Drinks are more than reason...</td>\n","    </tr>\n","    <tr>\n","      <th>100594</th>\n","      <td>100594</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>This is definitely my new favorite breakfast s...</td>\n","    </tr>\n","    <tr>\n","      <th>82884</th>\n","      <td>82884</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>I could no longer resist this goofy, red and w...</td>\n","    </tr>\n","    <tr>\n","      <th>67872</th>\n","      <td>67872</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>Would have been one star, but the management d...</td>\n","    </tr>\n","    <tr>\n","      <th>433429</th>\n","      <td>433429</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>The WiFi was spotty and slow at best, and the ...</td>\n","    </tr>\n","    <tr>\n","      <th>238911</th>\n","      <td>238911</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>My boyfriend and I went here last night on a r...</td>\n","    </tr>\n","    <tr>\n","      <th>214899</th>\n","      <td>214899</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>As far as national fast food chains go - Wendy...</td>\n","    </tr>\n","    <tr>\n","      <th>128768</th>\n","      <td>128768</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>I use to enjoy this place alot, I would recomm...</td>\n","    </tr>\n","    <tr>\n","      <th>76021</th>\n","      <td>76021</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>My boyfriend who hasn't lived here long was in...</td>\n","    </tr>\n","    <tr>\n","      <th>416723</th>\n","      <td>416723</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>I love the decor in this place. Everything fro...</td>\n","    </tr>\n","    <tr>\n","      <th>207101</th>\n","      <td>207101</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>If you've got 3 Hours to waste! This is your p...</td>\n","    </tr>\n","    <tr>\n","      <th>4139</th>\n","      <td>4139</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>If you are in the mood for German food, look n...</td>\n","    </tr>\n","    <tr>\n","      <th>474592</th>\n","      <td>474592</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>Yes I am a CJ's fan, have been since they brou...</td>\n","    </tr>\n","    <tr>\n","      <th>549708</th>\n","      <td>549708</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>Came here with a friend last week. Wait time w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            id  label alpha                                               text\n","2430      2430      1     a  I didn't really know what to expect from Lidia...\n","331013  331013      0     a  We absolutely love Costa Vida, but I have to a...\n","510602  510602      0     a  The only reason we stayed at this place is bec...\n","364277  364277      0     a  This was the most over rated restaurant I have...\n","297591  297591      1     a  First time I came here it was the middle of Ju...\n","359799  359799      0     a  My son and I stood at the front for 6 mins. We...\n","447821  447821      1     a  Great little spot. Drinks are more than reason...\n","100594  100594      1     a  This is definitely my new favorite breakfast s...\n","82884    82884      0     a  I could no longer resist this goofy, red and w...\n","67872    67872      0     a  Would have been one star, but the management d...\n","433429  433429      0     a  The WiFi was spotty and slow at best, and the ...\n","238911  238911      0     a  My boyfriend and I went here last night on a r...\n","214899  214899      0     a  As far as national fast food chains go - Wendy...\n","128768  128768      0     a  I use to enjoy this place alot, I would recomm...\n","76021    76021      0     a  My boyfriend who hasn't lived here long was in...\n","416723  416723      1     a  I love the decor in this place. Everything fro...\n","207101  207101      0     a  If you've got 3 Hours to waste! This is your p...\n","4139      4139      1     a  If you are in the mood for German food, look n...\n","474592  474592      1     a  Yes I am a CJ's fan, have been since they brou...\n","549708  549708      1     a  Came here with a friend last week. Wait time w..."]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"rpWb2-Awzsix","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"84599231-95f8-4885-9b25-d21686dc5af8","executionInfo":{"status":"ok","timestamp":1572124047154,"user_tz":-330,"elapsed":49415,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["\n","dev_df = pd.DataFrame({\n","    'id':range(len(test_df)),\n","    'label':test_df[0],\n","    'alpha':['a']*test_df.shape[0],\n","    'text': test_df[1].replace(r'\\n', ' ', regex=True)\n","})\n","\n","dev_df.head()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>label</th>\n","      <th>alpha</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>Contrary to other reviews, I have zero complai...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>Last summer I had an appointment to get new ti...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>Friendly staff, same starbucks fair you get an...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>a</td>\n","      <td>The food is good. Unfortunately the service is...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>a</td>\n","      <td>Even when we didn't have a car Filene's Baseme...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  label alpha                                               text\n","0   0      1     a  Contrary to other reviews, I have zero complai...\n","1   1      0     a  Last summer I had an appointment to get new ti...\n","2   2      1     a  Friendly staff, same starbucks fair you get an...\n","3   3      0     a  The food is good. Unfortunately the service is...\n","4   4      1     a  Even when we didn't have a car Filene's Baseme..."]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"zsP76kt0zRQ5","colab_type":"code","colab":{}},"source":["train_df.to_csv('data/train.tsv', sep='\\t', index=False, header=False, columns=train_df.columns)\n","dev_df.to_csv('data/dev.tsv', sep='\\t', index=False, header=False, columns=dev_df.columns)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vsJsf7Xtz6hm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"f85c0174-1047-4613-c8d0-6fc08f3cd6bc","executionInfo":{"status":"ok","timestamp":1572124061590,"user_tz":-330,"elapsed":63826,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["! wget https://raw.githubusercontent.com/ThilinaRajapakse/pytorch-transformers-classification/master/utils.py"],"execution_count":12,"outputs":[{"output_type":"stream","text":["--2019-10-26 21:07:38--  https://raw.githubusercontent.com/ThilinaRajapakse/pytorch-transformers-classification/master/utils.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10461 (10K) [text/plain]\n","Saving to: ‘utils.py’\n","\n","\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]  10.22K  --.-KB/s    in 0s      \n","\n","2019-10-26 21:07:39 (82.6 MB/s) - ‘utils.py’ saved [10461/10461]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vOBP0lhJzTjg","colab_type":"code","colab":{}},"source":["from __future__ import absolute_import, division, print_function\n","\n","import glob\n","import logging\n","import os\n","import random\n","import json\n","\n","import numpy as np\n","import torch\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","import random\n","from torch.utils.data.distributed import DistributedSampler\n","from tqdm import tqdm_notebook, trange\n","\n","\n","from pytorch_transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer,\n","                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n","                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n","                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n","\n","from pytorch_transformers import AdamW, WarmupLinearSchedule\n","\n","from utils import (convert_examples_to_features,\n","                        output_modes, processors)\n","\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(__name__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8cjQ-1hmzVgv","colab_type":"code","colab":{}},"source":["args = {\n","    'data_dir': 'data/',\n","    'model_type':  'roberta',\n","    'model_name': 'roberta-base',\n","    'task_name': 'binary',\n","    'output_dir': 'outputs/',\n","    'cache_dir': 'cache/',\n","    'do_train': True,\n","    'do_eval': True,\n","    'fp16': False,\n","    'fp16_opt_level': 'O1',\n","    'max_seq_length': 128,\n","    'output_mode': 'classification',\n","    'train_batch_size': 8,\n","    'eval_batch_size': 8,\n","\n","    'gradient_accumulation_steps': 1,\n","    'num_train_epochs': 1,\n","    'weight_decay': 0,\n","    'learning_rate': 4e-5,\n","    'adam_epsilon': 1e-8,\n","    'warmup_steps': 0,\n","    'max_grad_norm': 1.0,\n","\n","    'logging_steps': 50,\n","    'evaluate_during_training': False,\n","    'save_steps': 2000,\n","    'eval_all_checkpoints': True,\n","\n","    'overwrite_output_dir': False,\n","    'reprocess_input_data': False,\n","    'notes': 'Using Yelp Reviews dataset'\n","}\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P98pzOLI0LwU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"outputId":"85b2ab1d-0d3b-4241-8551-8e8daf5479de","executionInfo":{"status":"ok","timestamp":1572124063545,"user_tz":-330,"elapsed":65755,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["args\n"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'adam_epsilon': 1e-08,\n"," 'cache_dir': 'cache/',\n"," 'data_dir': 'data/',\n"," 'do_eval': True,\n"," 'do_train': True,\n"," 'eval_all_checkpoints': True,\n"," 'eval_batch_size': 8,\n"," 'evaluate_during_training': False,\n"," 'fp16': False,\n"," 'fp16_opt_level': 'O1',\n"," 'gradient_accumulation_steps': 1,\n"," 'learning_rate': 4e-05,\n"," 'logging_steps': 50,\n"," 'max_grad_norm': 1.0,\n"," 'max_seq_length': 128,\n"," 'model_name': 'roberta-base',\n"," 'model_type': 'roberta',\n"," 'notes': 'Using Yelp Reviews dataset',\n"," 'num_train_epochs': 1,\n"," 'output_dir': 'outputs/',\n"," 'output_mode': 'classification',\n"," 'overwrite_output_dir': False,\n"," 'reprocess_input_data': False,\n"," 'save_steps': 2000,\n"," 'task_name': 'binary',\n"," 'train_batch_size': 8,\n"," 'warmup_steps': 0,\n"," 'weight_decay': 0}"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"nxO30X-60NeF","colab_type":"code","colab":{}},"source":["with open('args.json', 'w') as f:\n","    json.dump(args, f)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XZKGAvM-0OpS","colab_type":"code","colab":{}},"source":["if os.path.exists(args['output_dir']) and os.listdir(args['output_dir']) and args['do_train'] and not args['overwrite_output_dir']:\n","    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args['output_dir']))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wDZgbQRY0QBO","colab_type":"code","colab":{}},"source":["\n","MODEL_CLASSES = {\n","    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n","    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n","    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n","    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n","}\n","\n","config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"egN-iaH30Rxf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":700},"outputId":"33e10d1d-beda-4910-d419-983124c1cd90","executionInfo":{"status":"ok","timestamp":1572124070101,"user_tz":-330,"elapsed":72274,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["\n","config = config_class.from_pretrained(args['model_name'], num_labels=2, finetuning_task=args['task_name'])\n","tokenizer = tokenizer_class.from_pretrained(args['model_name'])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json not found in cache or force_download set to True, downloading to /tmp/tmp2fxsnj5s\n","100%|██████████| 473/473 [00:00<00:00, 175737.96B/s]\n","INFO:pytorch_transformers.file_utils:copying /tmp/tmp2fxsnj5s to cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n","INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n","INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmp2fxsnj5s\n","INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n","INFO:pytorch_transformers.modeling_utils:Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": \"binary\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json not found in cache or force_download set to True, downloading to /tmp/tmpob8zfnvs\n","100%|██████████| 898823/898823 [00:01<00:00, 823906.56B/s]\n","INFO:pytorch_transformers.file_utils:copying /tmp/tmpob8zfnvs to cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmpob8zfnvs\n","INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt not found in cache or force_download set to True, downloading to /tmp/tmp38lb9zgm\n","100%|██████████| 456318/456318 [00:00<00:00, 500180.43B/s]\n","INFO:pytorch_transformers.file_utils:copying /tmp/tmp38lb9zgm to cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n","INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmp38lb9zgm\n","INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json from cache at /root/.cache/torch/pytorch_transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b\n","INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt from cache at /root/.cache/torch/pytorch_transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"bTsUPHbL0VFO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":547},"outputId":"8a31bf67-edcd-4937-9e99-d6fa77b80a17","executionInfo":{"status":"ok","timestamp":1572124122620,"user_tz":-330,"elapsed":124782,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["model = model_class.from_pretrained(args['model_name'])\n"],"execution_count":20,"outputs":[{"output_type":"stream","text":["INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-config.json from cache at /root/.cache/torch/pytorch_transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.9dad9043216064080cf9dd3711c53c0f11fe2b09313eaa66931057b4bdcaf068\n","INFO:pytorch_transformers.modeling_utils:Model config {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"pruned_heads\": {},\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 1,\n","  \"vocab_size\": 50265\n","}\n","\n","INFO:pytorch_transformers.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpq4cp3sme\n","100%|██████████| 501200538/501200538 [00:44<00:00, 11292599.49B/s]\n","INFO:pytorch_transformers.file_utils:copying /tmp/tmpq4cp3sme to cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","INFO:pytorch_transformers.file_utils:creating metadata file for /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","INFO:pytorch_transformers.file_utils:removing temp file /tmp/tmpq4cp3sme\n","INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/228756ed15b6d200d7cb45aaef08c087e2706f54cb912863d2efe07c89584eb7.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e\n","INFO:pytorch_transformers.modeling_utils:Weights of RobertaForSequenceClassification not initialized from pretrained model: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n","INFO:pytorch_transformers.modeling_utils:Weights from pretrained model not used in RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JuDhtqWS0WkS","colab_type":"code","colab":{}},"source":["model.to(device);\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWU0Mp_R0Zxc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5038de06-d3ed-47fe-fb09-7d8f528d0d8d","executionInfo":{"status":"ok","timestamp":1572124127986,"user_tz":-330,"elapsed":130125,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["device\n"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"dFGpnro90axM","colab_type":"code","colab":{}},"source":["\n","task = args['task_name']\n","\n","processor = processors[task]()\n","label_list = processor.get_labels()\n","num_labels = len(label_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZQAxPgY0cH1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3ba2f17f-99ad-4090-ca46-8f00de404c16","executionInfo":{"status":"ok","timestamp":1572124127988,"user_tz":-330,"elapsed":130106,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["task"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'binary'"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"XrDCYl4n0dQw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e3c1933a-cd20-4b48-b47a-13e7f99cf3d8","executionInfo":{"status":"ok","timestamp":1572124127989,"user_tz":-330,"elapsed":130092,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["num_labels"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"7TPVQnwW0e9N","colab_type":"code","colab":{}},"source":["def load_and_cache_examples(task, tokenizer, evaluate=False, undersample_scale_factor=0.01):\n","    processor = processors[task]()\n","    output_mode = args['output_mode']\n","    \n","    mode = 'dev' if evaluate else 'train'\n","    cached_features_file = os.path.join(args['data_dir'], f\"cached_{mode}_{args['model_name']}_{args['max_seq_length']}_{task}\")\n","    \n","    if os.path.exists(cached_features_file) and not args['reprocess_input_data']:\n","        logger.info(\"Loading features from cached file %s\", cached_features_file)\n","        features = torch.load(cached_features_file)\n","               \n","    else:\n","        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n","        label_list = processor.get_labels()\n","        examples = processor.get_dev_examples(args['data_dir']) if evaluate else processor.get_train_examples(args['data_dir'])\n","        print(len(examples))\n","        examples  = [example for example in examples if np.random.rand() < undersample_scale_factor]\n","        print(len(examples))\n","        \n","        features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n","            cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n","            cls_token=tokenizer.cls_token,\n","            sep_token=tokenizer.sep_token,\n","            cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n","            pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n","            pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0,\n","            process_count=2)\n","        \n","        logger.info(\"Saving features into cached file %s\", cached_features_file)\n","        torch.save(features, cached_features_file)\n","        \n","    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n","    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n","    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n","    if output_mode == \"classification\":\n","        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n","    elif output_mode == \"regression\":\n","        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n","\n","    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n","    return dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d_cA6IwQ1RhN","colab_type":"code","colab":{}},"source":["\n","\n","def train(train_dataset, model, tokenizer):\n","    train_sampler = RandomSampler(train_dataset)\n","    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=args['train_batch_size'])\n","    \n","    t_total = len(train_dataloader) // args['gradient_accumulation_steps'] * args['num_train_epochs']\n","    \n","    no_decay = ['bias', 'LayerNorm.weight']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': args['weight_decay']},\n","        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","        ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=args['adam_epsilon'])\n","    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=args['warmup_steps'], t_total=t_total)\n","    \n","    if args['fp16']:\n","        try:\n","            from apex import amp\n","        except ImportError:\n","            raise ImportError(\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\")\n","        model, optimizer = amp.initialize(model, optimizer, opt_level=args['fp16_opt_level'])\n","        \n","    logger.info(\"***** Running training *****\")\n","    logger.info(\"  Num examples = %d\", len(train_dataset))\n","    logger.info(\"  Num Epochs = %d\", args['num_train_epochs'])\n","    logger.info(\"  Total train batch size  = %d\", args['train_batch_size'])\n","    logger.info(\"  Gradient Accumulation steps = %d\", args['gradient_accumulation_steps'])\n","    logger.info(\"  Total optimization steps = %d\", t_total)\n","\n","    global_step = 0\n","    tr_loss, logging_loss = 0.0, 0.0\n","    model.zero_grad()\n","    train_iterator = trange(int(args['num_train_epochs']), desc=\"Epoch\")\n","    \n","    for _ in train_iterator:\n","        epoch_iterator = tqdm_notebook(train_dataloader, desc=\"Iteration\")\n","        for step, batch in enumerate(epoch_iterator):\n","            model.train()\n","            batch = tuple(t.to(device) for t in batch)\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n","                      'labels':         batch[3]}\n","            outputs = model(**inputs)\n","            loss = outputs[0]  # model outputs are always tuple in pytorch-transformers (see doc)\n","            print(\"\\r%f\" % loss, end='')\n","\n","            if args['gradient_accumulation_steps'] > 1:\n","                loss = loss / args['gradient_accumulation_steps']\n","\n","            if args['fp16']:\n","                with amp.scale_loss(loss, optimizer) as scaled_loss:\n","                    scaled_loss.backward()\n","                torch.nn.utils.clip_grad_norm_(amp.master_params(optimizer), args['max_grad_norm'])\n","                \n","            else:\n","                loss.backward()\n","                torch.nn.utils.clip_grad_norm_(model.parameters(), args['max_grad_norm'])\n","\n","            tr_loss += loss.item()\n","            if (step + 1) % args['gradient_accumulation_steps'] == 0:\n","                scheduler.step()  # Update learning rate schedule\n","                optimizer.step()\n","                model.zero_grad()\n","                global_step += 1\n","\n","                if args['logging_steps'] > 0 and global_step % args['logging_steps'] == 0:\n","                    # Log metrics\n","                    if args['evaluate_during_training']:  # Only evaluate when single GPU otherwise metrics may not average well\n","                        results = evaluate(model, tokenizer)\n","\n","                    logging_loss = tr_loss\n","\n","                if args['save_steps'] > 0 and global_step % args['save_steps'] == 0:\n","                    # Save model checkpoint\n","                    output_dir = os.path.join(args['output_dir'], 'checkpoint-{}'.format(global_step))\n","                    if not os.path.exists(output_dir):\n","                        os.makedirs(output_dir)\n","                    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","                    model_to_save.save_pretrained(output_dir)\n","                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n","\n","\n","    return global_step, tr_loss / global_step"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpRmmkL21Ual","colab_type":"code","colab":{}},"source":["from sklearn.metrics import mean_squared_error, matthews_corrcoef, confusion_matrix\n","from scipy.stats import pearsonr\n","\n","def get_mismatched(labels, preds):\n","    mismatched = labels != preds\n","    examples = processor.get_dev_examples(args['data_dir'])\n","    wrong = [i for (i, v) in zip(examples, mismatched) if v]\n","    \n","    return wrong\n","\n","def get_eval_report(labels, preds):\n","    mcc = matthews_corrcoef(labels, preds)\n","    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n","    return {\n","        \"mcc\": mcc,\n","        \"tp\": tp,\n","        \"tn\": tn,\n","        \"fp\": fp,\n","        \"fn\": fn\n","    }, get_mismatched(labels, preds)\n","\n","def compute_metrics(task_name, preds, labels):\n","    assert len(preds) == len(labels)\n","    return get_eval_report(labels, preds)\n","\n","def evaluate(model, tokenizer, prefix=\"\"):\n","    # Loop to handle MNLI double evaluation (matched, mis-matched)\n","    eval_output_dir = args['output_dir']\n","\n","    results = {}\n","    EVAL_TASK = args['task_name']\n","\n","    eval_dataset = load_and_cache_examples(EVAL_TASK, tokenizer, evaluate=True)\n","    if not os.path.exists(eval_output_dir):\n","        os.makedirs(eval_output_dir)\n","\n","\n","    eval_sampler = SequentialSampler(eval_dataset)\n","    eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=args['eval_batch_size'])\n","\n","    # Eval!\n","    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n","    logger.info(\"  Num examples = %d\", len(eval_dataset))\n","    logger.info(\"  Batch size = %d\", args['eval_batch_size'])\n","    eval_loss = 0.0\n","    nb_eval_steps = 0\n","    preds = None\n","    out_label_ids = None\n","    for batch in tqdm_notebook(eval_dataloader, desc=\"Evaluating\"):\n","        model.eval()\n","        batch = tuple(t.to(device) for t in batch)\n","\n","        with torch.no_grad():\n","            inputs = {'input_ids':      batch[0],\n","                      'attention_mask': batch[1],\n","                      'token_type_ids': batch[2] if args['model_type'] in ['bert', 'xlnet'] else None,  # XLM don't use segment_ids\n","                      'labels':         batch[3]}\n","            outputs = model(**inputs)\n","            tmp_eval_loss, logits = outputs[:2]\n","\n","            eval_loss += tmp_eval_loss.mean().item()\n","        nb_eval_steps += 1\n","        if preds is None:\n","            preds = logits.detach().cpu().numpy()\n","            out_label_ids = inputs['labels'].detach().cpu().numpy()\n","        else:\n","            preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n","            out_label_ids = np.append(out_label_ids, inputs['labels'].detach().cpu().numpy(), axis=0)\n","\n","    eval_loss = eval_loss / nb_eval_steps\n","    if args['output_mode'] == \"classification\":\n","        preds = np.argmax(preds, axis=1)\n","    elif args['output_mode'] == \"regression\":\n","        preds = np.squeeze(preds)\n","    result, wrong = compute_metrics(EVAL_TASK, preds, out_label_ids)\n","    results.update(result)\n","\n","    output_eval_file = os.path.join(eval_output_dir, \"eval_results.txt\")\n","    with open(output_eval_file, \"w\") as writer:\n","        logger.info(\"***** Eval results {} *****\".format(prefix))\n","        for key in sorted(result.keys()):\n","            logger.info(\"  %s = %s\", key, str(result[key]))\n","            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n","\n","    return results, wrong"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DYgIKMtK1mwE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":360},"outputId":"7ad3b88f-85ef-4652-c67e-474d7dc448b6","executionInfo":{"status":"ok","timestamp":1572127529128,"user_tz":-330,"elapsed":3531191,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["# IMPORTANT #\n","# Due to the 12 hour limit on Google Colab and the time it would take to convert the dataset into features, the load_and_cache_examples() function has been modified\n","# to randomly undersample the dataset by a scale of 0.1\n","\n","if args['do_train']:\n","    train_dataset = load_and_cache_examples(task, tokenizer, undersample_scale_factor=0.1)\n","    global_step, tr_loss = train(train_dataset, model, tokenizer)\n","    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["INFO:__main__:Creating features from dataset file at data/\n"],"name":"stderr"},{"output_type":"stream","text":["560000\n","56484\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 56484/56484 [01:26<00:00, 651.75it/s]\n","INFO:__main__:Saving features into cached file data/cached_train_roberta-base_128_binary\n","INFO:__main__:***** Running training *****\n","INFO:__main__:  Num examples = 56484\n","INFO:__main__:  Num Epochs = 1\n","INFO:__main__:  Total train batch size  = 8\n","INFO:__main__:  Gradient Accumulation steps = 1\n","INFO:__main__:  Total optimization steps = 7061\n","Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"644ac34e86b048e891e06e84ea7dbb3c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Iteration', max=7061, style=ProgressStyle(description_width='…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r0.684129"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["0.621388"],"name":"stdout"},{"output_type":"stream","text":["INFO:__main__:Saving model checkpoint to outputs/checkpoint-2000\n"],"name":"stderr"},{"output_type":"stream","text":["0.093531"],"name":"stdout"},{"output_type":"stream","text":["INFO:__main__:Saving model checkpoint to outputs/checkpoint-4000\n"],"name":"stderr"},{"output_type":"stream","text":["0.002124"],"name":"stdout"},{"output_type":"stream","text":["INFO:__main__:Saving model checkpoint to outputs/checkpoint-6000\n"],"name":"stderr"},{"output_type":"stream","text":["0.011944"],"name":"stdout"},{"output_type":"stream","text":["\rEpoch: 100%|██████████| 1/1 [54:56<00:00, 3296.24s/it]\n","INFO:__main__: global_step = 7061, average loss = 0.2774866830898933\n"],"name":"stderr"},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TrXQxf6J1qaF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e8b087ac-f82a-400d-e60e-580d1fa3e5d0","executionInfo":{"status":"ok","timestamp":1572127530938,"user_tz":-330,"elapsed":3532990,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["if args['do_train']:\n","    if not os.path.exists(args['output_dir']):\n","            os.makedirs(args['output_dir'])\n","    logger.info(\"Saving model checkpoint to %s\", args['output_dir'])\n","    \n","    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","    model_to_save.save_pretrained(args['output_dir'])\n","    tokenizer.save_pretrained(args['output_dir'])\n","    torch.save(args, os.path.join(args['output_dir'], 'training_args.bin'))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["INFO:__main__:Saving model checkpoint to outputs/\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"hhrbgPBS1rvG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"768f5c5e-d584-4d50-a8bf-7cbc5bd21adc","executionInfo":{"status":"error","timestamp":1572153923171,"user_tz":-330,"elapsed":1107,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}}},"source":["tr_loss"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-8323bb798931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'tr_loss' is not defined"]}]},{"cell_type":"code","metadata":{"id":"gbfS1iiTrRFv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}