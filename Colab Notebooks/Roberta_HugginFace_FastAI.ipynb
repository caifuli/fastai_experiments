{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai_hugginface.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4fsdNsAmjmM",
        "colab_type": "text"
      },
      "source": [
        "POC for hugginface and fastai. \n",
        "\n",
        "Currently POC for dataset: sentiment-analysis-on-movie-reviews\n",
        "Model: Roberta\n",
        "\n",
        "[Tutorial](https://towardsdatascience.com/fastai-with-transformers-bert-roberta-xlnet-xlm-distilbert-4f41ee18ecb2)\n",
        "\n",
        "This does not work directly for BERT. \n",
        "Tutorial does not specify instructions for GPT-2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmVZEHPIcahH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install transformers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CKPrQE7m6WE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH_Ys0Q9cieR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "0bad170b-90fd-4673-ee9e-3dc55b150efa"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from pathlib import Path \n",
        "\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "import random \n",
        "\n",
        "# fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "\n",
        "# transformers\n",
        "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1_12WXgcue_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6e2e1455-b728-446f-e20c-c42f71c2335d"
      },
      "source": [
        "import fastai\n",
        "import transformers\n",
        "print('fastai version :', fastai.__version__)\n",
        "print('transformers version :', transformers.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fastai version : 1.0.59\n",
            "transformers version : 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uekpcAidnvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "a7e1143f-9a64-4005-d104-e1a0f64b7ff4"
      },
      "source": [
        "!pip install kaggle\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/bb20f9b9e24f9a6250f95a432f8d9a7d745f8d24039d7a5a6eaadb7783ba/kaggle-1.5.6.tar.gz (58kB)\n",
            "\r\u001b[K     |█████▋                          | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.9.11)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.6-cp36-none-any.whl size=72859 sha256=0fad62f1e00eab84158cae96f7c9fe540f5646387c6b4066b9032d3e07368955\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/4e/e8/bb28d035162fb8f17f8ca5d42c3230e284c6aa565b42b72674\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nirdniQedtmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo '{\"username\":\"chaatuur\",\"key\":\"00dc407c5744c7ac9bced8c9bbcf459b\"}' > ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6mbkXvNgio0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "416mlpkucz5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "30f04a17-ea33-4d9c-e538-62c3bd475bd6"
      },
      "source": [
        "! kaggle competitions download -c sentiment-analysis-on-movie-reviews"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sentiment-analysis-on-movie-reviews.zip to /content\n",
            "\r  0% 0.00/1.90M [00:00<?, ?B/s]\n",
            "\r100% 1.90M/1.90M [00:00<00:00, 154MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rQzuDopdE13",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "150129e8-4d3c-44b3-c500-32be7cebf286"
      },
      "source": [
        "! ls -lrt "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 14108\n",
            "-rw-r--r-- 1 root root 8481022 May  3  2018 train.tsv\n",
            "-rw-r--r-- 1 root root 3367149 May  3  2018 test.tsv\n",
            "-rw-r--r-- 1 root root  596647 May  3  2018 sampleSubmission.csv\n",
            "drwxr-xr-x 1 root root    4096 Nov 21 16:30 sample_data\n",
            "-rw-r--r-- 1 root root 1990207 Dec  3 06:48 sentiment-analysis-on-movie-reviews.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuJqa1zUeCgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2834fca1-e1c1-4fa6-e2ee-0da65a361ae4"
      },
      "source": [
        "! unzip sentiment-analysis-on-movie-reviews.zip"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sentiment-analysis-on-movie-reviews.zip\n",
            "  inflating: sampleSubmission.csv    \n",
            "  inflating: train.tsv               \n",
            "  inflating: test.tsv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZIQZpW0hP4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_ROOT = Path(\".\")\n",
        "train = pd.read_csv(DATA_ROOT / 'train.tsv', sep=\"\\t\")\n",
        "test = pd.read_csv(DATA_ROOT / 'test.tsv', sep=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9efPyVKhdTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
        "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
        "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
        "from transformers import XLMForSequenceClassification, XLMTokenizer, XLMConfig\n",
        "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "\n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
        "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
        "    'xlm': (XLMForSequenceClassification, XLMTokenizer, XLMConfig),\n",
        "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
        "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)}\n",
        "    \n",
        "model_type = 'roberta'\n",
        "\n",
        "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAGc9e6-hlxB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f6310adc-6bd6-4c38-f655-5c9d250ca2ac"
      },
      "source": [
        "class TransformersBaseTokenizer(BaseTokenizer):\n",
        "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
        "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
        "        self._pretrained_tokenizer = pretrained_tokenizer\n",
        "        self.max_seq_len = pretrained_tokenizer.max_len\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def __call__(self, *args, **kwargs): \n",
        "        return self\n",
        "\n",
        "    def tokenizer(self, t:str) -> List[str]:\n",
        "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
        "        CLS = self._pretrained_tokenizer.cls_token\n",
        "        SEP = self._pretrained_tokenizer.sep_token\n",
        "        if self.model_type in ['roberta']:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
        "        else:\n",
        "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
        "        return [CLS] + tokens + [SEP]\n",
        "        \n",
        "model_name = 'roberta-base'\n",
        "transformer_tokenizer = tokenizer_class.from_pretrained(model_name)\n",
        "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
        "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 898823/898823 [00:01<00:00, 811276.31B/s]\n",
            "100%|██████████| 456318/456318 [00:00<00:00, 506778.16B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKoPLv4lhu3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TransformersVocab(Vocab):\n",
        "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
        "        super(TransformersVocab, self).__init__(itos = [])\n",
        "        self.tokenizer = tokenizer\n",
        "    \n",
        "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
        "        \"Convert a list of tokens `t` to their ids.\"\n",
        "        return self.tokenizer.convert_tokens_to_ids(t)\n",
        "        #return self.tokenizer.encode(t)\n",
        "\n",
        "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
        "        \"Convert a list of `nums` to their tokens.\"\n",
        "        nums = np.array(nums).tolist()\n",
        "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94uZojjPiXDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
        "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
        "\n",
        "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, \n",
        "                                       include_bos=False, \n",
        "                                       include_eos=False)\n",
        "\n",
        "transformer_processor = [tokenize_processor, numericalize_processor]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV7qNTE2jMuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "use_fp16 = False\n",
        "bs = 16\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nycRWzWsjFIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_first = bool(model_type in ['xlnet'])\n",
        "pad_idx = transformer_tokenizer.pad_token_id\n",
        "\n",
        "databunch = (TextList.from_df(train, cols='Phrase', processor=transformer_processor)\n",
        "             .split_by_rand_pct(0.1,seed=seed)\n",
        "             .label_from_df(cols= 'Sentiment')\n",
        "             .add_test(test)\n",
        "             .databunch(bs=bs, pad_first=pad_first, pad_idx=pad_idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGBq2NHZjIyA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomTransformerModel(nn.Module):\n",
        "  \n",
        "    def __init__(self, transformer_model: PreTrainedModel):\n",
        "        super(CustomTransformerModel,self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        \n",
        "    def forward(self, input_ids):\n",
        "        # Return only the logits from the transfomer\n",
        "        logits = self.transformer(input_ids)[0]   \n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3wsuZNBjUAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f59c9b10-49c9-423b-badb-db505836e63d"
      },
      "source": [
        "config = config_class.from_pretrained(model_name)\n",
        "config.num_labels = 5\n",
        "\n",
        "transformer_model = model_class.from_pretrained(model_name, config = config)\n",
        "# transformer_model = model_class.from_pretrained(model_name, num_labels = 5)\n",
        "custom_transformer_model = CustomTransformerModel(transformer_model = transformer_model)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 473/473 [00:00<00:00, 263641.97B/s]\n",
            "100%|██████████| 501200538/501200538 [00:40<00:00, 12402174.31B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clKE7Dj0jmMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW\n",
        "learner = Learner(databunch, \n",
        "                  custom_transformer_model, \n",
        "                  opt_func = lambda input: AdamW(input, correct_bias=False), \n",
        "                  metrics=[accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnV8fbq4jsKb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b582044e-02ec-4fd1-f7e2-7826332fb7d7"
      },
      "source": [
        "list_layers = [learner.model.transformer.distilbert.embeddings,\n",
        "               learner.model.transformer.distilbert.transformer.layer[0] ,\n",
        "               learner.model.transformer.distilbert.transformer.layer[1],\n",
        "               learner.model.transformer.distilbert.transformer.layer[2],\n",
        "               learner.model.transformer.distilbert.transformer.layer[3],\n",
        "               learner.model.transformer.distilbert.transformer.layer[4],\n",
        "               learner.model.transformer.distilbert.transformer.layer[5],\n",
        "               learner.model.transformer.pre_classifier]\n",
        "               \n",
        "learner.split(list_layers)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-6e578086306d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m list_layers = [learner.model.transformer.distilbert.embeddings,\n\u001b[0m\u001b[1;32m      2\u001b[0m                \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistilbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistilbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistilbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistilbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 585\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'RobertaForSequenceClassification' object has no attribute 'distilbert'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCYVBbhPkODT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.freeze_to(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SyCQ-vck8QL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "30bace7c-2d7a-46b7-9d1d-c0d8695365d3"
      },
      "source": [
        "learner.lr_find()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxGd0KChlG2k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "6aa55eeb-86a5-4160-ac5c-40972b7651c4"
      },
      "source": [
        "learner.recorder.plot()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYKlLpaEmRLl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "outputId": "70289822-8482-48a1-8b66-5c89b3cbbb89"
      },
      "source": [
        "learner.fit_one_cycle(1,max_lr=2e-03,moms=(0.8,0.7))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.00% [0/1 00:00<00:00]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='50' class='' max='8778', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.57% [50/8778 02:39<7:44:48 1.3115]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SACeSWHmXzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}